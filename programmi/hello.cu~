#include <stdio.h>
#include <stdlib.h>
#include <iostream>
#include <cuda.h>
 
using namespace std;
 
 
#define imin(a,b) (a<b?a:b)
 
 
const int N = 1*1024;
const int threadsPerBlock = 512;
const int blocksPerGrid = imin(32,(N+threadsPerBlock-1)/threadsPerBlock);
 
 
__global__ void dot( float *a, float *b, float *c ) {
 
  __shared__ float cache[threadsPerBlock];
   
  int tid = threadIdx.x + blockIdx.x * blockDim.x;
  int cacheIndex = threadIdx.x;
 
  float   temp = 0;
  while (tid < N) {
      temp += a[tid] * b[tid];
      tid += blockDim.x * gridDim.x;
  }
 
  cache[cacheIndex] = temp;
   
  __syncthreads();
 
  int i = blockDim.x/2;
  while (i != 0) {
      if (cacheIndex < i){
      cache[cacheIndex] += cache[cacheIndex + i];
      }
      __syncthreads();
      i /= 2;
  }
 
  if (cacheIndex == 0){
      c[blockIdx.x] = cache[0];
  }
   
}
 
 
int main( void ) {
  cout << "dot product" << endl;
  float   *a, *b, c, *partial_c; 
  float   *dev_a, *dev_b, *dev_partial_c;  
 
  a = new float[N];
  b = new float[N];
  partial_c = new float[N];
 
  for (int i=0; i<N; i++) {
      a[i] = i;
      b[i] = i*2.0f;
  }
 
 
   cudaMalloc( (void**)&dev_a, N*sizeof(float) ) ;
   cudaMalloc( (void**)&dev_b, N*sizeof(float) ) ;
   cudaMalloc( (void**)&dev_partial_c, blocksPerGrid*sizeof(float) ) ;
 
   cudaMemcpy( dev_a, a, N*sizeof(float), cudaMemcpyHostToDevice ) ;
   cudaMemcpy( dev_b, b, N*sizeof(float), cudaMemcpyHostToDevice ) ; 
 
  dot<<<blocksPerGrid,threadsPerBlock>>>( dev_a, dev_b, dev_partial_c );
 
   cudaMemcpy( partial_c, dev_partial_c, blocksPerGrid*sizeof(float),cudaMemcpyDeviceToHost ) ;
 
  c = 0;
  for (int i=0; i<blocksPerGrid; i++) {
      c += partial_c[i];
  }
 
  //checks result in CPU
  #define sum_sq(x)  (x*(x+1)*(2*x+1)/6)
  float result = 2 * sum_sq( (float)(N - 1) );
  cout << " GPU: " << c << endl;
  cout << " CPU: " << result << endl;
 
 
   cudaFree( dev_a ) ;
   cudaFree( dev_b ) ;
   cudaFree( dev_partial_c ) ;
 
  delete[] a;
  delete[] b;
  delete[] partial_c;
}
